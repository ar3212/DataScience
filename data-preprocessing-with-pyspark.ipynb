{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-01-16T07:55:54.179327Z",
     "iopub.status.busy": "2021-01-16T07:55:54.178548Z",
     "iopub.status.idle": "2021-01-16T07:55:54.195573Z",
     "shell.execute_reply": "2021-01-16T07:55:54.194836Z"
    },
    "papermill": {
     "duration": 0.036182,
     "end_time": "2021-01-16T07:55:54.195692",
     "exception": false,
     "start_time": "2021-01-16T07:55:54.159510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/flights-and-airports-data/airports.csv\n",
      "/kaggle/input/flights-and-airports-data/flights.csv\n",
      "/kaggle/input/flights-and-airports-data/raw-flight-data.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-01-16T07:55:54.216544Z",
     "iopub.status.busy": "2021-01-16T07:55:54.215604Z",
     "iopub.status.idle": "2021-01-16T07:56:33.186503Z",
     "shell.execute_reply": "2021-01-16T07:56:33.185413Z"
    },
    "papermill": {
     "duration": 38.982529,
     "end_time": "2021-01-16T07:56:33.186623",
     "exception": false,
     "start_time": "2021-01-16T07:55:54.204094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\r\n",
      "  Downloading pyspark-3.0.1.tar.gz (204.2 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 204.2 MB 33 kB/s \r\n",
      "\u001b[?25hCollecting py4j==0.10.9\r\n",
      "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 198 kB 36.1 MB/s \r\n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\r\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.0.1-py2.py3-none-any.whl size=204612244 sha256=2344d2920ebe25cf1b46d7b995dd4292093d966b285e459e5e6320de6ce2c2b7\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/5e/34/fa/b37b5cef503fc5148b478b2495043ba61b079120b7ff379f9b\r\n",
      "Successfully built pyspark\r\n",
      "Installing collected packages: py4j, pyspark\r\n",
      "Successfully installed py4j-0.10.9 pyspark-3.0.1\r\n",
      "\u001b[33mWARNING: You are using pip version 20.3.1; however, version 20.3.3 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-16T07:56:33.407278Z",
     "iopub.status.busy": "2021-01-16T07:56:33.406259Z",
     "iopub.status.idle": "2021-01-16T07:56:33.595730Z",
     "shell.execute_reply": "2021-01-16T07:56:33.596261Z"
    },
    "papermill": {
     "duration": 0.303553,
     "end_time": "2021-01-16T07:56:33.596412",
     "exception": false,
     "start_time": "2021-01-16T07:56:33.292859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-16T07:56:33.815728Z",
     "iopub.status.busy": "2021-01-16T07:56:33.815092Z",
     "iopub.status.idle": "2021-01-16T07:56:40.790222Z",
     "shell.execute_reply": "2021-01-16T07:56:40.789473Z"
    },
    "papermill": {
     "duration": 7.086787,
     "end_time": "2021-01-16T07:56:40.790363",
     "exception": false,
     "start_time": "2021-01-16T07:56:33.703576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Turning On Big machine\n",
    "Spark=SparkSession.builder.master('local').appName(\"Warm Up Pyspark\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-16T07:56:41.060647Z",
     "iopub.status.busy": "2021-01-16T07:56:41.059855Z",
     "iopub.status.idle": "2021-01-16T07:56:53.811925Z",
     "shell.execute_reply": "2021-01-16T07:56:53.811169Z"
    },
    "papermill": {
     "duration": 12.896706,
     "end_time": "2021-01-16T07:56:53.812073",
     "exception": false,
     "start_time": "2021-01-16T07:56:40.915367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|DayofMonth|DayOfWeek|Carrier|OriginAirportID|DestAirportID|DepDelay|ArrDelay|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|        19|        5|     DL|          11433|        13303|      -3|       1|\n",
      "|        19|        5|     DL|          14869|        12478|       0|      -8|\n",
      "|        19|        5|     DL|          14057|        14869|      -4|     -15|\n",
      "|        19|        5|     DL|          15016|        11433|      28|      24|\n",
      "|        19|        5|     DL|          11193|        12892|      -6|     -11|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------+-----------+-----+--------------------+\n",
      "|airport_id|       city|state|                name|\n",
      "+----------+-----------+-----+--------------------+\n",
      "|     10165|Adak Island|   AK|                Adak|\n",
      "|     10299|  Anchorage|   AK|Ted Stevens Ancho...|\n",
      "|     10304|      Aniak|   AK|       Aniak Airport|\n",
      "|     10754|     Barrow|   AK|Wiley Post/Will R...|\n",
      "|     10551|     Bethel|   AK|      Bethel Airport|\n",
      "+----------+-----------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Load the dataset\n",
    "dataflight=Spark.read.csv(\"../input/flights-and-airports-data/raw-flight-data.csv\", inferSchema=True, header=True)\n",
    "dataairport=Spark.read.csv(\"../input/flights-and-airports-data/airports.csv\", inferSchema=True,header=True)\n",
    "dataflight.show(5)\n",
    "dataairport.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-16T07:56:53.991401Z",
     "iopub.status.busy": "2021-01-16T07:56:53.990929Z",
     "iopub.status.idle": "2021-01-16T07:56:54.006955Z",
     "shell.execute_reply": "2021-01-16T07:56:54.007566Z"
    },
    "papermill": {
     "duration": 0.100557,
     "end_time": "2021-01-16T07:56:54.007700",
     "exception": false,
     "start_time": "2021-01-16T07:56:53.907143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DayofMonth: integer (nullable = true)\n",
      " |-- DayOfWeek: integer (nullable = true)\n",
      " |-- Carrier: string (nullable = true)\n",
      " |-- OriginAirportID: integer (nullable = true)\n",
      " |-- DestAirportID: integer (nullable = true)\n",
      " |-- DepDelay: integer (nullable = true)\n",
      " |-- ArrDelay: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataflight.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-16T07:56:54.190912Z",
     "iopub.status.busy": "2021-01-16T07:56:54.190200Z",
     "iopub.status.idle": "2021-01-16T07:57:02.198387Z",
     "shell.execute_reply": "2021-01-16T07:57:02.200573Z"
    },
    "papermill": {
     "duration": 8.098033,
     "end_time": "2021-01-16T07:57:02.200765",
     "exception": false,
     "start_time": "2021-01-16T07:56:54.102732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|          City|count|\n",
      "+--------------+-----+\n",
      "|       Phoenix|90281|\n",
      "|         Omaha|13537|\n",
      "|Raleigh/Durham|28436|\n",
      "|     Anchorage| 7777|\n",
      "|        Dallas|19503|\n",
      "+--------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Lets Join two table\n",
    "FlightbyOrigin=dataflight.join(dataairport,dataflight.OriginAirportID==dataairport.airport_id).groupby('City').count()\n",
    "FlightbyOrigin.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-16T07:57:02.489535Z",
     "iopub.status.busy": "2021-01-16T07:57:02.488139Z",
     "iopub.status.idle": "2021-01-16T07:57:37.450401Z",
     "shell.execute_reply": "2021-01-16T07:57:37.451016Z"
    },
    "papermill": {
     "duration": 35.093944,
     "end_time": "2021-01-16T07:57:37.451157",
     "exception": false,
     "start_time": "2021-01-16T07:57:02.357213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data All 2719418\n",
      "Data Distinct 2696983\n",
      "Data Duplicate 22435\n"
     ]
    }
   ],
   "source": [
    "#Deal with Duplicate\n",
    "print(\"Data All\",dataflight.count())\n",
    "print(\"Data Distinct\", dataflight.dropDuplicates().count())\n",
    "print(\"Data Duplicate\", dataflight.count()-dataflight.dropDuplicates().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-16T07:57:37.675569Z",
     "iopub.status.busy": "2021-01-16T07:57:37.674772Z",
     "iopub.status.idle": "2021-01-16T07:57:52.457346Z",
     "shell.execute_reply": "2021-01-16T07:57:52.456238Z"
    },
    "papermill": {
     "duration": 14.898497,
     "end_time": "2021-01-16T07:57:52.457486",
     "exception": false,
     "start_time": "2021-01-16T07:57:37.558989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Value: 46233\n"
     ]
    }
   ],
   "source": [
    "#Dealing With Missing Value\n",
    "flightnomissingvalue=dataflight.dropDuplicates().dropna(how='any').count()\n",
    "print(\"Missing Value:\",dataflight.count()-flightnomissingvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-16T07:57:52.688456Z",
     "iopub.status.busy": "2021-01-16T07:57:52.687695Z",
     "iopub.status.idle": "2021-01-16T07:57:58.712424Z",
     "shell.execute_reply": "2021-01-16T07:57:58.711846Z"
    },
    "papermill": {
     "duration": 6.138628,
     "end_time": "2021-01-16T07:57:58.712537",
     "exception": false,
     "start_time": "2021-01-16T07:57:52.573909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-----------------+\n",
      "|summary|         DepDelay|         ArrDelay|\n",
      "+-------+-----------------+-----------------+\n",
      "|  count|          2691974|          2690385|\n",
      "|   mean|10.53686662649788| 6.63768791455498|\n",
      "| stddev|36.09952806642889|38.64881489390084|\n",
      "|    min|              -63|              -94|\n",
      "|    max|             1863|             1845|\n",
      "+-------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Statistics \n",
    "FlightbyOrigin1=dataflight.join(dataairport,dataflight.OriginAirportID==dataairport.airport_id)\n",
    "FlightbyOrigin1.describe('DepDelay','ArrDelay').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 130.550219,
   "end_time": "2021-01-16T07:57:58.959378",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-16T07:55:48.409159",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
